{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>selftext</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>realize pretty vague honestly mind long simply...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Trying to source house track I heard on dubpla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>know long shot looking song month luck hoping ...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Does anyone have a copy of Rene Breitbarth - \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>post dedicated finding unknown unidentifiable ...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>Welcome to our weekly post for song/track IDs....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>kind remix like best d</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Looking for a really good remix of \"Foreigner ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>like minimal micro house playlist you perfect ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Minimal House / Deep Tech Playlist (Submission...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>4861</td>\n",
       "      <td>76648</td>\n",
       "      <td>looking house track long drum break conga djem...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Looking for tracks with percussive drum breaks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4862</th>\n",
       "      <td>4862</td>\n",
       "      <td>76784</td>\n",
       "      <td>trying get year contacted label said would sho...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Need Some Help Finding a Rare Tiger &amp;amp; Wood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4863</th>\n",
       "      <td>4863</td>\n",
       "      <td>76797</td>\n",
       "      <td>time year yearly round best music year rule si...</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>r/House's 2016 Favourites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4864</th>\n",
       "      <td>4864</td>\n",
       "      <td>76800</td>\n",
       "      <td>mine in particular order hard omar s heard che...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>Your favourite tracks of the year 2016?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4865</th>\n",
       "      <td>4865</td>\n",
       "      <td>76851</td>\n",
       "      <td>hey guy first post reddit please bare making m...</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>Is jackmaster super overrated ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4866 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  index                                           selftext  \\\n",
       "0              0     11  realize pretty vague honestly mind long simply...   \n",
       "1              1     21  know long shot looking song month luck hoping ...   \n",
       "2              2     49  post dedicated finding unknown unidentifiable ...   \n",
       "3              3     91                             kind remix like best d   \n",
       "4              4    111  like minimal micro house playlist you perfect ...   \n",
       "...          ...    ...                                                ...   \n",
       "4861        4861  76648  looking house track long drum break conga djem...   \n",
       "4862        4862  76784  trying get year contacted label said would sho...   \n",
       "4863        4863  76797  time year yearly round best music year rule si...   \n",
       "4864        4864  76800  mine in particular order hard omar s heard che...   \n",
       "4865        4865  76851  hey guy first post reddit please bare making m...   \n",
       "\n",
       "      num_comments  score                                              title  \n",
       "0                0      1  Trying to source house track I heard on dubpla...  \n",
       "1                5      3  Does anyone have a copy of Rene Breitbarth - \"...  \n",
       "2                9      4  Welcome to our weekly post for song/track IDs....  \n",
       "3                2      1  Looking for a really good remix of \"Foreigner ...  \n",
       "4                0      3  Minimal House / Deep Tech Playlist (Submission...  \n",
       "...            ...    ...                                                ...  \n",
       "4861             0      1     Looking for tracks with percussive drum breaks  \n",
       "4862             4      1  Need Some Help Finding a Rare Tiger &amp; Wood...  \n",
       "4863            13     17                          r/House's 2016 Favourites  \n",
       "4864             3     11            Your favourite tracks of the year 2016?  \n",
       "4865            16      2                    Is jackmaster super overrated ?  \n",
       "\n",
       "[4866 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"cleaned_house.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_other(x):\n",
    "    x = re.sub(\"\\$\",\" \", x) #remove $\n",
    "    x = re.sub(\"https*\\S+\", \" \", x) #remove url\n",
    "    #x = re.sub(\"\\'\\w+\", '', x) #remove i'm,we're,let's after the '\n",
    "    #x = re.sub(\"[0-9]+\", '', x) #remove numbers\n",
    "    x = x.encode('ascii', 'ignore').decode()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "def lemmatize(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    nwords=[]\n",
    "    for word in words:\n",
    "        word=lemmatizer.lemmatize(word)\n",
    "        nwords.append(word)\n",
    "    return ' '.join(nwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>realize pretty vague honestly mind long simply...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>know long shot looking song month luck hoping ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>post dedicated finding unknown unidentifiable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>kind remix like best d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>like minimal micro house playlist you perfect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>4861</td>\n",
       "      <td>looking house track long drum break conga djem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>4862</td>\n",
       "      <td>trying get year contacted label said would sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>4863</td>\n",
       "      <td>time year yearly round best music year rule si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>4864</td>\n",
       "      <td>mine in particular order hard omar s heard che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>4865</td>\n",
       "      <td>hey guy first post reddit please bare making m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4287 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text\n",
       "0         0  realize pretty vague honestly mind long simply...\n",
       "1         1  know long shot looking song month luck hoping ...\n",
       "2         2  post dedicated finding unknown unidentifiable ...\n",
       "3         3                             kind remix like best d\n",
       "4         4  like minimal micro house playlist you perfect ...\n",
       "...     ...                                                ...\n",
       "4282   4861  looking house track long drum break conga djem...\n",
       "4283   4862  trying get year contacted label said would sho...\n",
       "4284   4863  time year yearly round best music year rule si...\n",
       "4285   4864  mine in particular order hard omar s heard che...\n",
       "4286   4865  hey guy first post reddit please bare making m...\n",
       "\n",
       "[4287 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=pd.DataFrame({'text':df['selftext']})\n",
    "X = X.dropna().reset_index()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>acid</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>advance</th>\n",
       "      <th>ago</th>\n",
       "      <th>album</th>\n",
       "      <th>amazing</th>\n",
       "      <th>amp xb</th>\n",
       "      <th>...</th>\n",
       "      <th>woman</th>\n",
       "      <th>wondering</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>xb</th>\n",
       "      <th>year</th>\n",
       "      <th>year ago</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.355724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233473</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.15038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133915</td>\n",
       "      <td>0.068470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4287 rows Ã— 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          able  absolutely     acid  actually  add  advance  ago     album  \\\n",
       "0     0.000000    0.000000  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "1     0.355724    0.000000  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "2     0.000000    0.000000  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "3     0.000000    0.000000  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "4     0.000000    0.000000  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "...        ...         ...      ...       ...  ...      ...  ...       ...   \n",
       "4282  0.000000    0.000000  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "4283  0.000000    0.233473  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "4284  0.000000    0.000000  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "4285  0.000000    0.000000  0.15038       0.0  0.0      0.0  0.0  0.133915   \n",
       "4286  0.000000    0.000000  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "\n",
       "       amazing    amp xb  ...  woman  wondering  word  work  working  world  \\\n",
       "0     0.000000  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "1     0.000000  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "2     0.000000  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "3     0.000000  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "4     0.000000  0.243245  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "...        ...       ...  ...    ...        ...   ...   ...      ...    ...   \n",
       "4282  0.000000  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "4283  0.211949  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "4284  0.000000  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "4285  0.068470  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "4286  0.000000  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "\n",
       "            xb      year  year ago  youtube  \n",
       "0     0.000000  0.000000       0.0      0.0  \n",
       "1     0.000000  0.000000       0.0      0.0  \n",
       "2     0.000000  0.000000       0.0      0.0  \n",
       "3     0.000000  0.000000       0.0      0.0  \n",
       "4     0.243245  0.000000       0.0      0.0  \n",
       "...        ...       ...       ...      ...  \n",
       "4282  0.000000  0.000000       0.0      0.0  \n",
       "4283  0.000000  0.317682       0.0      0.0  \n",
       "4284  0.000000  0.292003       0.0      0.0  \n",
       "4285  0.000000  0.153940       0.0      0.0  \n",
       "4286  0.000000  0.000000       0.0      0.0  \n",
       "\n",
       "[4287 rows x 367 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#analyzer=â€˜char_wbâ€™\n",
    "vec=TfidfVectorizer(min_df=0.01,stop_words='english',ngram_range=(1,2))\n",
    "counts=vec.fit_transform(X['text'])\n",
    "counts=counts.toarray()\n",
    "count_df1=pd.DataFrame(counts,columns=vec.get_feature_names())\n",
    "count_df1=count_df1.drop(['amp'],axis=1)\n",
    "count_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(init='random', n_components=3, random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model1=NMF(n_components=3,init=\"random\",random_state=0)\n",
    "model1.fit(count_df1)\n",
    "#model1.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def top_words(X, model, component, num_words):\n",
    "    \"\"\"\n",
    "    Extract the top words from the specified component \n",
    "    for a topic model trained on data. \n",
    "    X: a term-document matrix, assumed to be a pd.DataFrame\n",
    "    model: a sklearn model with a components_ attribute, e.g. NMF\n",
    "    component: the desired component, specified as an integer. \n",
    "        Must be less than than the total number of components in model\n",
    "    num_words: the number of words to return.\n",
    "    \"\"\"\n",
    "    orders = np.argsort(model.components_, axis = 1)\n",
    "    important_words = np.array(X.columns)[orders]\n",
    "    return important_words[component][-num_words:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>really</td>\n",
       "      <td>new</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love</td>\n",
       "      <td>know track</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>looking</td>\n",
       "      <td>lt</td>\n",
       "      <td>remix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>house music</td>\n",
       "      <td>enjoy</td>\n",
       "      <td>original mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>know</td>\n",
       "      <td>hope</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>like</td>\n",
       "      <td>feedback</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>music</td>\n",
       "      <td>track</td>\n",
       "      <td>dj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>song</td>\n",
       "      <td>video</td>\n",
       "      <td>listen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>track</td>\n",
       "      <td>xb</td>\n",
       "      <td>soundcloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>house</td>\n",
       "      <td>amp xb</td>\n",
       "      <td>mix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Topic 0     Topic 1       Topic 2\n",
       "0       really         new          live\n",
       "1         love  know track          link\n",
       "2      looking          lt         remix\n",
       "3  house music       enjoy  original mix\n",
       "4         know        hope      original\n",
       "5         like    feedback      released\n",
       "6        music       track            dj\n",
       "7         song       video        listen\n",
       "8        track          xb    soundcloud\n",
       "9        house      amp xb           mix"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic1=pd.DataFrame({'Topic 0':top_words(count_df1, model1, 0, 10),\n",
    "                   'Topic 1':top_words(count_df1, model1, 1, 10),\n",
    "                   'Topic 2':top_words(count_df1, model1, 2, 10)})\n",
    "topic1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 0: social security/pension \\\n",
    "Topic 1: social media/life \\\n",
    "Topic 2: post/social medium/ins/facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=model1.fit_transform(count_df1)\n",
    "L=[]\n",
    "for i in W:\n",
    "    L.append(i.argmax())\n",
    "X['topic']=L\n",
    "t0=X[X.topic==0]\n",
    "t1=X[X.topic==1]\n",
    "t2=X[X.topic==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Emotion across topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_df(df):\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "    import my_module\n",
    "    import importlib\n",
    "    importlib.reload(my_module)\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    #create a list of dictionaries\n",
    "    sia = SIA()\n",
    "    results = []\n",
    "    words=[]\n",
    "\n",
    "    for line in df['text']:\n",
    "        D,pol_score=sid.polarity_scores(sia,text=line) #use customized module\n",
    "        pol_score['text'] = line\n",
    "        results.append(pol_score)\n",
    "        words.append(D)\n",
    "    #Extract sentiment words\n",
    "    D_p=[] # positive word and its sentiment score\n",
    "    D_n=[] # negative word and its sentiment score\n",
    "    D1=[] # only positive word\n",
    "    D2=[] # only negative word\n",
    "    for i in range(len(words)):\n",
    "        newDict = {key: value for (key, value) in words[i].items() if value != 0.0 }\n",
    "        newDict1 = {key: value for (key, value) in words[i].items() if value > 0.0 }\n",
    "        newDict2 = {key: value for (key, value) in words[i].items() if value < 0.0 }\n",
    "        D_p.append(newDict1)\n",
    "        D_n.append(newDict2)\n",
    "        D1.append(list(newDict1.keys()))\n",
    "        D2.append(list(newDict2.keys()))\n",
    "    #create a df to write in the results of sentiment analysis\n",
    "    sent = pd.DataFrame(results)\n",
    "    sent['p_word_dict']=D_p\n",
    "    sent['n_word_dict']=D_n\n",
    "    p=[]\n",
    "    n=[]\n",
    "    for i in D1:\n",
    "        p.append(' '.join(i))\n",
    "    for i in D2:\n",
    "        n.append(' '.join(i))\n",
    "    sent['total']=(sent.pos-sent.neg)/sent.neu    \n",
    "    sent['p_word']=p\n",
    "    sent['n_word']=n\n",
    "    sent['label']=0\n",
    "    sent['label'].loc[sent['total']> 0]=1\n",
    "    sent['label'].loc[sent['total']< 0]=-1\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'my_module' has no attribute 'polarity_scores'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-5cd8cf7b58cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msent_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'topic'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msent_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'topic'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-6a9b3ff34cd8>\u001b[0m in \u001b[0;36msent_df\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpol_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msia\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#use customized module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mpol_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpol_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'my_module' has no attribute 'polarity_scores'"
     ]
    }
   ],
   "source": [
    "a=sent_df(t0)\n",
    "a['topic']=0\n",
    "\n",
    "b=sent_df(t1)\n",
    "b['topic']=1\n",
    "\n",
    "c=sent_df(t2)\n",
    "c['topic']=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1079.000000\n",
       "mean        0.066820\n",
       "std         0.419285\n",
       "min       -10.904762\n",
       "25%        -0.006572\n",
       "50%         0.071811\n",
       "75%         0.191186\n",
       "max         2.571429\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=pd.concat([a,b,c],axis=0)\n",
    "final.total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    191.000000\n",
       "mean       0.066849\n",
       "std        0.177781\n",
       "min       -0.612903\n",
       "25%       -0.004834\n",
       "50%        0.044632\n",
       "75%        0.162797\n",
       "max        0.818182\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Sentiment Score'), Text(0.5, 1.0, 'Sentiment Score by topics')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.boxplot(x=\"topic\", y=\"total\", data=final,showfliers = False)\n",
    "ax.set(ylabel=\"Sentiment Score\",title=\"Sentiment Score by topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common positive/negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_pn(df):\n",
    "    positive=df.p_word[df['label']==1] #positive words in positive post\n",
    "    negative=df.n_word[df['label']==-1] #negative words in negative post\n",
    "    return positive,negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import collections\n",
    "def count_words(text):\n",
    "    all_words = list(itertools.chain(*text.str.split()))\n",
    "    counts = collections.Counter(all_words)\n",
    "    counts_df = pd.DataFrame(counts.most_common(100),\n",
    "                            columns=['words', 'count'])\n",
    "\n",
    "    return counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>security</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>like</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ha</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>number</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>friend</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>want</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pay</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      words  count\n",
       "0  security    231\n",
       "1      like    104\n",
       "2        ha     91\n",
       "3    number     65\n",
       "4    friend     55\n",
       "0   anxiety     38\n",
       "1        no     33\n",
       "2       bad     16\n",
       "3      want     14\n",
       "4       pay     13"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive,negative=sort_pn(final)\n",
    "p_n=pd.concat([count_words(positive)[:5],count_words(negative)[:5]])\n",
    "p_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>security</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>number</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ha</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benefit</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pay</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>security</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>want</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unemployment</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          words  count\n",
       "0      security    229\n",
       "1        number     59\n",
       "2            ha     31\n",
       "3          like     17\n",
       "4       benefit     17\n",
       "0           pay      6\n",
       "1            no      6\n",
       "2      security      4\n",
       "3          want      3\n",
       "4  unemployment      3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive,negative=sort_pn(a)\n",
    "p_n=pd.concat([count_words(positive)[:5],count_words(negative)[:5]])\n",
    "p_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>friend</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ha</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>help</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>awkward</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problem</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     words  count\n",
       "0     like     68\n",
       "1   friend     40\n",
       "2       ha     39\n",
       "3     good     32\n",
       "4     help     19\n",
       "0  anxiety     38\n",
       "1       no     22\n",
       "2      bad     15\n",
       "3  awkward     10\n",
       "4  problem     10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive,negative=sort_pn(b)\n",
    "p_n=pd.concat([count_words(positive)[:5],count_words(negative)[:5]])\n",
    "p_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ha</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>like</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>friend</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>want</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>struggling</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>teasing</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>want</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blocked</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words  count\n",
       "0          ha     21\n",
       "1        like     19\n",
       "2      friend     13\n",
       "3        good     12\n",
       "4        want      8\n",
       "0          no      5\n",
       "1  struggling      3\n",
       "2     teasing      3\n",
       "3        want      3\n",
       "4     blocked      2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive,negative=sort_pn(c)\n",
    "p_n=pd.concat([count_words(positive)[:5],count_words(negative)[:5]])\n",
    "p_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequency splitted by sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#nltk.download(\"stopwords\") #uncomment it when run it for the first time\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "stop_words.update({'would','k','im','could','also',\n",
    "                   'amp','much','one','like','get',\n",
    "                   'since','etc','got','always',\n",
    "                   'know','thing','really','dont',\n",
    "                   'find','even','go','time','need','want'\n",
    "                  })\n",
    "def remove_stopwords(text):\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "final['text']=final['text'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "def count_2gram(text):\n",
    "    all_words = list(itertools.chain(*text.str.split()))\n",
    "    es2grams = ngrams(all_words, 2)\n",
    "    counts = collections.Counter(es2grams)\n",
    "    count_df = pd.DataFrame(counts.most_common(100),\n",
    "                            columns=['words', 'count'])\n",
    "    dictionary2 = [' '.join(tup) for tup in count_df.words]\n",
    "    count_df.words=dictionary2\n",
    "\n",
    "    return count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1079.000000\n",
       "mean        0.066820\n",
       "std         0.419285\n",
       "min       -10.904762\n",
       "25%        -0.006572\n",
       "50%         0.071811\n",
       "75%         0.191186\n",
       "max         2.571429\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(              words  count\n",
       " 0   social security    237\n",
       " 1     social medium    123\n",
       " 2              I wa     41\n",
       " 3   security number     30\n",
       " 4       social life     30\n",
       " 5     social media,     29\n",
       " 6            I feel     28\n",
       " 7  social security.     25\n",
       " 8  social security,     21\n",
       " 9           I think     20,\n",
       "              words  count\n",
       " 0    social medium     50\n",
       " 1             I wa     27\n",
       " 2  social security     25\n",
       " 3   social anxiety     20\n",
       " 4           I feel     15\n",
       " 5      social life     11\n",
       " 6    social media,     10\n",
       " 7          I can't      9\n",
       " 8     social life.      8\n",
       " 9         I social      8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pn_freq(df):\n",
    "    count_p=count_2gram(df['text'][df['label']>0.191186]) #>0.109797 #==1\n",
    "    count_n=count_2gram(df['text'][df['label']<-0.006572]) #<-0.001208 #==-1\n",
    "    return count_p,count_n\n",
    "\n",
    "p,n=pn_freq(final)\n",
    "p.head(10),n.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(              words  count\n",
       " 0   social security    235\n",
       " 1   security number     30\n",
       " 2  social security.     25\n",
       " 3  social security,     21\n",
       " 4     security card     14\n",
       " 5              I wa     13\n",
       " 6  security number.     13\n",
       " 7  security benefit     12\n",
       " 8          I social     10\n",
       " 9  security number,     10,\n",
       "                 words  count\n",
       " 0     social security     25\n",
       " 1            I called      4\n",
       " 2   birth certificate      3\n",
       " 3       security card      3\n",
       " 4     security number      3\n",
       " 5   security medicare      3\n",
       " 6    social security,      3\n",
       " 7                I wa      2\n",
       " 8         going start      2\n",
       " 9  certificate social      2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p,n=pn_freq(final[final.topic==0])\n",
    "p.head(10),n.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           words  count\n",
       " 0    social life     30\n",
       " 1         I feel     26\n",
       " 2           I wa     25\n",
       " 3  social media,     23\n",
       " 4        I think     12\n",
       " 5  social media.     12\n",
       " 6         feel I      9\n",
       " 7        I can't      8\n",
       " 8   social event      8\n",
       " 9          I see      8,\n",
       "                words  count\n",
       " 0               I wa     24\n",
       " 1     social anxiety     20\n",
       " 2             I feel     15\n",
       " 3        social life     11\n",
       " 4      social media,     10\n",
       " 5       social life.      8\n",
       " 6            I think      8\n",
       " 7      social media.      8\n",
       " 8    social anxiety.      7\n",
       " 9  social distancing      7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p,n=pn_freq(final[final.topic==1])\n",
    "p.head(10),n.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(               words  count\n",
       " 0      social medium    118\n",
       " 1     medium account      6\n",
       " 2      social media,      6\n",
       " 3            field -      4\n",
       " 4           I social      4\n",
       " 5      social media.      4\n",
       " 6         lot people      4\n",
       " 7  something related      3\n",
       " 8      related field      3\n",
       " 9       spend social      3,\n",
       "                 words  count\n",
       " 0       social medium     46\n",
       " 1       Sales running      3\n",
       " 2      running social      3\n",
       " 3   medium campaigns,      3\n",
       " 4  campaigns, product      3\n",
       " 5   product marketing      3\n",
       " 6   marketing putting      3\n",
       " 7        putting blog      3\n",
       " 8           blog post      3\n",
       " 9      post podcasts,      3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p,n=pn_freq(final[final.topic==2])\n",
    "p.head(10),n.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling after sentiment splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1079.000000\n",
       "mean        0.066820\n",
       "std         0.419285\n",
       "min       -10.904762\n",
       "25%        -0.006572\n",
       "50%         0.071811\n",
       "75%         0.191186\n",
       "max         2.571429\n",
       "Name: total, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>2020</th>\n",
       "      <th>401k</th>\n",
       "      <th>able</th>\n",
       "      <th>account</th>\n",
       "      <th>actually</th>\n",
       "      <th>address</th>\n",
       "      <th>adult</th>\n",
       "      <th>advice</th>\n",
       "      <th>...</th>\n",
       "      <th>worker</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>worth</th>\n",
       "      <th>wrong</th>\n",
       "      <th>x200b</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>youre</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.17634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103988</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.629796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>675 rows Ã— 361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     000   10  2020  401k  able   account  actually  address  adult  advice  \\\n",
       "0    0.0  0.0   0.0   0.0   0.0  0.152557       0.0      0.0    0.0     0.0   \n",
       "1    0.0  0.0   0.0   0.0   0.0  0.000000       0.0      0.0    0.0     0.0   \n",
       "2    0.0  0.0   0.0   0.0   0.0  0.000000       0.0      0.0    0.0     0.0   \n",
       "3    0.0  0.0   0.0   0.0   0.0  0.000000       0.0      0.0    0.0     0.0   \n",
       "4    0.0  0.0   0.0   0.0   0.0  0.000000       0.0      0.0    0.0     0.0   \n",
       "..   ...  ...   ...   ...   ...       ...       ...      ...    ...     ...   \n",
       "670  0.0  0.0   0.0   0.0   0.0  0.000000       0.0      0.0    0.0     0.0   \n",
       "671  0.0  0.0   0.0   0.0   0.0  0.000000       0.0      0.0    0.0     0.0   \n",
       "672  0.0  0.0   0.0   0.0   0.0  0.000000       0.0      0.0    0.0     0.0   \n",
       "673  0.0  0.0   0.0   0.0   0.0  0.000000       0.0      0.0    0.0     0.0   \n",
       "674  0.0  0.0   0.0   0.0   0.0  0.000000       0.0      0.0    0.0     0.0   \n",
       "\n",
       "     ...  worker  working  world  worth  wrong  x200b      year    years  \\\n",
       "0    ...     0.0      0.0    0.0    0.0    0.0    0.0  0.000000  0.00000   \n",
       "1    ...     0.0      0.0    0.0    0.0    0.0    0.0  0.000000  0.00000   \n",
       "2    ...     0.0      0.0    0.0    0.0    0.0    0.0  0.000000  0.17634   \n",
       "3    ...     0.0      0.0    0.0    0.0    0.0    0.0  0.000000  0.00000   \n",
       "4    ...     0.0      0.0    0.0    0.0    0.0    0.0  0.103988  0.00000   \n",
       "..   ...     ...      ...    ...    ...    ...    ...       ...      ...   \n",
       "670  ...     0.0      0.0    0.0    0.0    0.0    0.0  0.000000  0.00000   \n",
       "671  ...     0.0      0.0    0.0    0.0    0.0    0.0  0.000000  0.00000   \n",
       "672  ...     0.0      0.0    0.0    0.0    0.0    0.0  0.000000  0.00000   \n",
       "673  ...     0.0      0.0    0.0    0.0    0.0    0.0  0.000000  0.00000   \n",
       "674  ...     0.0      0.0    0.0    0.0    0.0    0.0  0.000000  0.00000   \n",
       "\n",
       "     youre   youtube  \n",
       "0      0.0  0.000000  \n",
       "1      0.0  0.000000  \n",
       "2      0.0  0.000000  \n",
       "3      0.0  0.000000  \n",
       "4      0.0  0.000000  \n",
       "..     ...       ...  \n",
       "670    0.0  0.000000  \n",
       "671    0.0  0.000000  \n",
       "672    0.0  0.000000  \n",
       "673    0.0  0.629796  \n",
       "674    0.0  0.000000  \n",
       "\n",
       "[675 rows x 361 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec=TfidfVectorizer(min_df=0.01,stop_words='english',ngram_range=(1,2))\n",
    "counts=vec.fit_transform(final['text'][final['label']>0.191186]) #positive\n",
    "counts=counts.toarray()\n",
    "count_df1=pd.DataFrame(counts,columns=vec.get_feature_names())\n",
    "#count_df1=count_df1.drop(['amp','don'],axis=1)\n",
    "count_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(init='random', n_components=3, random_state=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model1=NMF(n_components=3,init=\"random\",random_state=1)\n",
    "model1.fit(count_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>month</td>\n",
       "      <td>video</td>\n",
       "      <td>feel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pension</td>\n",
       "      <td>app</td>\n",
       "      <td>im</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tax</td>\n",
       "      <td>make</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>card</td>\n",
       "      <td>use</td>\n",
       "      <td>wa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>income</td>\n",
       "      <td>stock</td>\n",
       "      <td>media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>security number</td>\n",
       "      <td>facebook</td>\n",
       "      <td>social media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>number</td>\n",
       "      <td>ha</td>\n",
       "      <td>social life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>social</td>\n",
       "      <td>social</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>security</td>\n",
       "      <td>medium</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>social security</td>\n",
       "      <td>social medium</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Topic 0        Topic 1       Topic 2\n",
       "0            month          video          feel\n",
       "1          pension            app            im\n",
       "2              tax           make        friend\n",
       "3             card            use            wa\n",
       "4           income          stock         media\n",
       "5  security number       facebook  social media\n",
       "6           number             ha   social life\n",
       "7           social         social        people\n",
       "8         security         medium          life\n",
       "9  social security  social medium        social"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic2=pd.DataFrame({'Topic 0':top_words(count_df1, model1, 0, 10),\n",
    "                   'Topic 1':top_words(count_df1, model1, 1, 10),\n",
    "                   'Topic 2':top_words(count_df1, model1, 2, 10)})\n",
    "topic2\n",
    "# 'Topic 4':top_words(count_df1, model1, 4, 10),\n",
    "#                     'Topic 5':top_words(count_df1, model1, 5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pay house/loan/car \\\n",
    "retirement \\\n",
    "credit card \\\n",
    "school friend feel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>200</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abuse</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>worried</th>\n",
       "      <th>wouldnt</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>year ago</th>\n",
       "      <th>year old</th>\n",
       "      <th>years</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.207212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302184</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows Ã— 444 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      10   12   15   20  200   30   50      able  absolutely  abuse  ...  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000         0.0    0.0  ...   \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.254997         0.0    0.0  ...   \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000         0.0    0.0  ...   \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000         0.0    0.0  ...   \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000         0.0    0.0  ...   \n",
       "..   ...  ...  ...  ...  ...  ...  ...       ...         ...    ...  ...   \n",
       "272  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000         0.0    0.0  ...   \n",
       "273  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000         0.0    0.0  ...   \n",
       "274  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000         0.0    0.0  ...   \n",
       "275  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000         0.0    0.0  ...   \n",
       "276  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000         0.0    0.0  ...   \n",
       "\n",
       "     world   worried  wouldnt     wrong  year  year ago  year old  years  \\\n",
       "0      0.0  0.000000      0.0  0.000000   0.0       0.0       0.0    0.0   \n",
       "1      0.0  0.000000      0.0  0.000000   0.0       0.0       0.0    0.0   \n",
       "2      0.0  0.000000      0.0  0.210541   0.0       0.0       0.0    0.0   \n",
       "3      0.0  0.207212      0.0  0.000000   0.0       0.0       0.0    0.0   \n",
       "4      0.0  0.000000      0.0  0.000000   0.0       0.0       0.0    0.0   \n",
       "..     ...       ...      ...       ...   ...       ...       ...    ...   \n",
       "272    0.0  0.000000      0.0  0.000000   0.0       0.0       0.0    0.0   \n",
       "273    0.0  0.000000      0.0  0.000000   0.0       0.0       0.0    0.0   \n",
       "274    0.0  0.000000      0.0  0.000000   0.0       0.0       0.0    0.0   \n",
       "275    0.0  0.000000      0.0  0.000000   0.0       0.0       0.0    0.0   \n",
       "276    0.0  0.000000      0.0  0.000000   0.0       0.0       0.0    0.0   \n",
       "\n",
       "        young  youre  \n",
       "0    0.000000    0.0  \n",
       "1    0.000000    0.0  \n",
       "2    0.000000    0.0  \n",
       "3    0.000000    0.0  \n",
       "4    0.000000    0.0  \n",
       "..        ...    ...  \n",
       "272  0.302184    0.0  \n",
       "273  0.000000    0.0  \n",
       "274  0.000000    0.0  \n",
       "275  0.000000    0.0  \n",
       "276  0.000000    0.0  \n",
       "\n",
       "[277 rows x 444 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec=TfidfVectorizer(min_df=0.01,stop_words='english',ngram_range=(1,2))\n",
    "counts=vec.fit_transform(final['text'][final['label']<-0.006572]) #negative\n",
    "counts=counts.toarray()\n",
    "count_df2=pd.DataFrame(counts,columns=vec.get_feature_names())\n",
    "#count_df1=count_df1.drop(['amp','don'],axis=1)\n",
    "count_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(init='random', n_components=3, random_state=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=NMF(n_components=3,init=\"random\",random_state=0)\n",
    "model2.fit(count_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>long</td>\n",
       "      <td>ive</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>media</td>\n",
       "      <td>make</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>social media</td>\n",
       "      <td>job</td>\n",
       "      <td>federal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people</td>\n",
       "      <td>depression</td>\n",
       "      <td>medicare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>social life</td>\n",
       "      <td>bad social</td>\n",
       "      <td>income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wa</td>\n",
       "      <td>anxiety social</td>\n",
       "      <td>pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>life</td>\n",
       "      <td>bad</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>social</td>\n",
       "      <td>social</td>\n",
       "      <td>tax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>social medium</td>\n",
       "      <td>social anxiety</td>\n",
       "      <td>security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>medium</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>social security</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Topic 0         Topic 1          Topic 2\n",
       "0           long             ive             card\n",
       "1          media            make            state\n",
       "2   social media             job          federal\n",
       "3         people      depression         medicare\n",
       "4    social life      bad social           income\n",
       "5             wa  anxiety social              pay\n",
       "6           life             bad           social\n",
       "7         social          social              tax\n",
       "8  social medium  social anxiety         security\n",
       "9         medium         anxiety  social security"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic3=pd.DataFrame({'Topic 0':top_words(count_df2, model2, 0, 10),\n",
    "                   'Topic 1':top_words(count_df2, model2, 1, 10),\n",
    "                   'Topic 2':top_words(count_df2, model2, 2, 10)})\n",
    "topic3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "live home/parent \\\n",
    "credit card and insurance \\\n",
    "retirement \\\n",
    "parent talking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all adj. related to parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "#nltk.download('punkt')\n",
    "sentence=df['selftext'].apply(lambda x: sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parent(sentence_ele):\n",
    "    L=[]\n",
    "    for i in sentence_ele:\n",
    "        if 'time' in i: \n",
    "            L.append(i)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_sentence=sentence.apply(lambda x: extract_parent(x))\n",
    "' '.join(parent_sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-eea6f49be0ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m39\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "tokens=nltk.word_tokenize(parent_sentence[39][1])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-d3ab67a198cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokens' is not defined"
     ]
    }
   ],
   "source": [
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')\n",
    "def extract_adj(sentence_ele):\n",
    "    adjs=[]\n",
    "    for i in sentence_ele:\n",
    "        tokens=nltk.word_tokenize(i)\n",
    "        df_type=pd.DataFrame(nltk.pos_tag(tokens),columns=['words', 'type'])\n",
    "        adjs=list(df_type[df_type.type=='JJ'].words)\n",
    "    return ' '.join(adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjs=parent_sentence.apply(lambda x: extract_adj(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        \n",
       "1        \n",
       "2        \n",
       "3        \n",
       "4        \n",
       "       ..\n",
       "1315     \n",
       "1316     \n",
       "1317     \n",
       "1318     \n",
       "1319     \n",
       "Name: selftext, Length: 1320, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "After pruning, no terms remain. Try a lower min_df or a higher max_df.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-64232679c296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcounts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcount_df1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \"\"\"\n\u001b[1;32m   1839\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1841\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 raise ValueError(\n\u001b[1;32m   1214\u001b[0m                     \"max_df corresponds to < documents than min_df\")\n\u001b[0;32m-> 1215\u001b[0;31m             X, self.stop_words_ = self._limit_features(X, vocabulary,\n\u001b[0m\u001b[1;32m   1216\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m                                                        \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_limit_features\u001b[0;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0mkept_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkept_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             raise ValueError(\"After pruning, no terms remain. Try a lower\"\n\u001b[0m\u001b[1;32m   1089\u001b[0m                              \" min_df or a higher max_df.\")\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkept_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoved_terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: After pruning, no terms remain. Try a lower min_df or a higher max_df."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec=TfidfVectorizer(max_df=0.5,min_df=0.01,stop_words='english',ngram_range=(1,2))\n",
    "counts=vec.fit_transform(adjs)\n",
    "counts=counts.toarray()\n",
    "count_df1=pd.DataFrame(counts,columns=vec.get_feature_names())\n",
    "#count_df1=count_df1.drop(['amp','don'],axis=1)\n",
    "count_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(init='random', n_components=3, random_state=0)"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model1=NMF(n_components=3,init=\"random\",random_state=0)\n",
    "model1.fit(count_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small</td>\n",
       "      <td>hard</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>current</td>\n",
       "      <td>great</td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great</td>\n",
       "      <td>current</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>free</td>\n",
       "      <td>possible</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>monthly</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sure</td>\n",
       "      <td>long</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>little</td>\n",
       "      <td>financial</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>financial</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>able</td>\n",
       "      <td>sure</td>\n",
       "      <td>monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>good</td>\n",
       "      <td>new</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic 0    Topic 1    Topic 2\n",
       "0      small       hard      great\n",
       "1    current      great    current\n",
       "2      great    current       hard\n",
       "3       free   possible       free\n",
       "4       high    monthly  financial\n",
       "5       sure       long       long\n",
       "6     little  financial       live\n",
       "7  financial     little     little\n",
       "8       able       sure    monthly\n",
       "9       good        new        old"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic1=pd.DataFrame({'Topic 0':top_words(count_df1, model1, 0, 10),\n",
    "                   'Topic 1':top_words(count_df1, model1, 1, 10),\n",
    "                   'Topic 2':top_words(count_df1, model1, 2, 10)})\n",
    "topic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>â€™</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>own</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>able</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>old</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>much</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>few</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>m</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>first</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>financial</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>last</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>due</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sure</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>next</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>little</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>*</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>high</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words  count\n",
       "0           â€™    347\n",
       "1         own    188\n",
       "2        good    155\n",
       "3       other    154\n",
       "4         new    143\n",
       "5        able    138\n",
       "6         old    137\n",
       "7        much    126\n",
       "8         few    126\n",
       "9           m    122\n",
       "10      first    122\n",
       "11  financial    119\n",
       "12          i    105\n",
       "13       last    103\n",
       "14        due    103\n",
       "15       sure     96\n",
       "16       next     93\n",
       "17     little     83\n",
       "18          *     82\n",
       "19       high     75"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of all words across rows\n",
    "import itertools\n",
    "import collections\n",
    "def count_words(text):\n",
    "    all_words = list(itertools.chain(*text.str.split()))\n",
    "    counts = collections.Counter(all_words)\n",
    "    counts_df = pd.DataFrame(counts.most_common(100),\n",
    "                            columns=['words', 'count'])\n",
    "\n",
    "    return counts_df\n",
    "count_words(adjs).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>able</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>old</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>financial</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>last</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>due</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sure</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>next</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       words  count\n",
       "0       good    155\n",
       "1        new    143\n",
       "2       able    138\n",
       "3        old    137\n",
       "4      first    122\n",
       "5  financial    119\n",
       "6       last    103\n",
       "7        due    103\n",
       "8       sure     96\n",
       "9       next     93"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words.update({'i','*','im','â€™','much'})\n",
    "adjs=adjs.apply(lambda x: remove_stopwords(x))\n",
    "count_df=count_words(adjs)\n",
    "count_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
