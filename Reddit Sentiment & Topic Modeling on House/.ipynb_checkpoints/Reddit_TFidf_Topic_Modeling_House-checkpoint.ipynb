{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>selftext</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>realize pretty vague honestly mind long simply...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Trying to source house track I heard on dubpla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>know long shot looking song month luck hoping ...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Does anyone have a copy of Rene Breitbarth - \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>post dedicated finding unknown unidentifiable ...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>Welcome to our weekly post for song/track IDs....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>kind remix like best d</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Looking for a really good remix of \"Foreigner ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>like minimal micro house playlist you perfect ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Minimal House / Deep Tech Playlist (Submission...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>4861</td>\n",
       "      <td>76648</td>\n",
       "      <td>looking house track long drum break conga djem...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Looking for tracks with percussive drum breaks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4862</th>\n",
       "      <td>4862</td>\n",
       "      <td>76784</td>\n",
       "      <td>trying get year contacted label said would sho...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Need Some Help Finding a Rare Tiger &amp;amp; Wood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4863</th>\n",
       "      <td>4863</td>\n",
       "      <td>76797</td>\n",
       "      <td>time year yearly round best music year rule si...</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>r/House's 2016 Favourites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4864</th>\n",
       "      <td>4864</td>\n",
       "      <td>76800</td>\n",
       "      <td>mine in particular order hard omar s heard che...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>Your favourite tracks of the year 2016?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4865</th>\n",
       "      <td>4865</td>\n",
       "      <td>76851</td>\n",
       "      <td>hey guy first post reddit please bare making m...</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>Is jackmaster super overrated ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4866 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  index                                           selftext  \\\n",
       "0              0     11  realize pretty vague honestly mind long simply...   \n",
       "1              1     21  know long shot looking song month luck hoping ...   \n",
       "2              2     49  post dedicated finding unknown unidentifiable ...   \n",
       "3              3     91                             kind remix like best d   \n",
       "4              4    111  like minimal micro house playlist you perfect ...   \n",
       "...          ...    ...                                                ...   \n",
       "4861        4861  76648  looking house track long drum break conga djem...   \n",
       "4862        4862  76784  trying get year contacted label said would sho...   \n",
       "4863        4863  76797  time year yearly round best music year rule si...   \n",
       "4864        4864  76800  mine in particular order hard omar s heard che...   \n",
       "4865        4865  76851  hey guy first post reddit please bare making m...   \n",
       "\n",
       "      num_comments  score                                              title  \n",
       "0                0      1  Trying to source house track I heard on dubpla...  \n",
       "1                5      3  Does anyone have a copy of Rene Breitbarth - \"...  \n",
       "2                9      4  Welcome to our weekly post for song/track IDs....  \n",
       "3                2      1  Looking for a really good remix of \"Foreigner ...  \n",
       "4                0      3  Minimal House / Deep Tech Playlist (Submission...  \n",
       "...            ...    ...                                                ...  \n",
       "4861             0      1     Looking for tracks with percussive drum breaks  \n",
       "4862             4      1  Need Some Help Finding a Rare Tiger &amp; Wood...  \n",
       "4863            13     17                          r/House's 2016 Favourites  \n",
       "4864             3     11            Your favourite tracks of the year 2016?  \n",
       "4865            16      2                    Is jackmaster super overrated ?  \n",
       "\n",
       "[4866 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"cleaned_house.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_other(x):\n",
    "    x = re.sub(\"\\$\",\" \", x) #remove $\n",
    "    x = re.sub(\"https*\\S+\", \" \", x) #remove url\n",
    "    #x = re.sub(\"\\'\\w+\", '', x) #remove i'm,we're,let's after the '\n",
    "    #x = re.sub(\"[0-9]+\", '', x) #remove numbers\n",
    "    x = x.encode('ascii', 'ignore').decode()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>realize pretty vague honestly mind long simply...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>know long shot looking song month luck hoping ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>post dedicated finding unknown unidentifiable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>kind remix like best d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>like minimal micro house playlist you perfect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>4861</td>\n",
       "      <td>looking house track long drum break conga djem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>4862</td>\n",
       "      <td>trying get year contacted label said would sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>4863</td>\n",
       "      <td>time year yearly round best music year rule si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>4864</td>\n",
       "      <td>mine in particular order hard omar s heard che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>4865</td>\n",
       "      <td>hey guy first post reddit please bare making m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4287 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text\n",
       "0         0  realize pretty vague honestly mind long simply...\n",
       "1         1  know long shot looking song month luck hoping ...\n",
       "2         2  post dedicated finding unknown unidentifiable ...\n",
       "3         3                             kind remix like best d\n",
       "4         4  like minimal micro house playlist you perfect ...\n",
       "...     ...                                                ...\n",
       "4282   4861  looking house track long drum break conga djem...\n",
       "4283   4862  trying get year contacted label said would sho...\n",
       "4284   4863  time year yearly round best music year rule si...\n",
       "4285   4864  mine in particular order hard omar s heard che...\n",
       "4286   4865  hey guy first post reddit please bare making m...\n",
       "\n",
       "[4287 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=pd.DataFrame({'text':df['selftext']})\n",
    "X = X.dropna().reset_index()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>acid</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>advance</th>\n",
       "      <th>ago</th>\n",
       "      <th>album</th>\n",
       "      <th>amazing</th>\n",
       "      <th>amp</th>\n",
       "      <th>...</th>\n",
       "      <th>woman</th>\n",
       "      <th>wondering</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>xb</th>\n",
       "      <th>year</th>\n",
       "      <th>year ago</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.355724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233473</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211949</td>\n",
       "      <td>0.129906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.15038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133915</td>\n",
       "      <td>0.068470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4287 rows Ã— 368 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          able  absolutely     acid  actually  add  advance  ago     album  \\\n",
       "0     0.000000    0.000000  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "1     0.355724    0.000000  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "2     0.000000    0.000000  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "3     0.000000    0.000000  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "4     0.000000    0.000000  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "...        ...         ...      ...       ...  ...      ...  ...       ...   \n",
       "4282  0.000000    0.000000  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "4283  0.000000    0.233473  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "4284  0.000000    0.000000  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "4285  0.000000    0.000000  0.15038       0.0  0.0      0.0  0.0  0.133915   \n",
       "4286  0.000000    0.000000  0.00000       0.0  0.0      0.0  0.0  0.000000   \n",
       "\n",
       "       amazing       amp  ...  woman  wondering  word  work  working  world  \\\n",
       "0     0.000000  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "1     0.000000  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "2     0.000000  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "3     0.000000  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "4     0.000000  0.205086  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "...        ...       ...  ...    ...        ...   ...   ...      ...    ...   \n",
       "4282  0.000000  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "4283  0.211949  0.129906  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "4284  0.000000  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "4285  0.068470  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "4286  0.000000  0.000000  ...    0.0        0.0   0.0   0.0      0.0    0.0   \n",
       "\n",
       "            xb      year  year ago  youtube  \n",
       "0     0.000000  0.000000       0.0      0.0  \n",
       "1     0.000000  0.000000       0.0      0.0  \n",
       "2     0.000000  0.000000       0.0      0.0  \n",
       "3     0.000000  0.000000       0.0      0.0  \n",
       "4     0.243245  0.000000       0.0      0.0  \n",
       "...        ...       ...       ...      ...  \n",
       "4282  0.000000  0.000000       0.0      0.0  \n",
       "4283  0.000000  0.317682       0.0      0.0  \n",
       "4284  0.000000  0.292003       0.0      0.0  \n",
       "4285  0.000000  0.153940       0.0      0.0  \n",
       "4286  0.000000  0.000000       0.0      0.0  \n",
       "\n",
       "[4287 rows x 368 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#analyzer=â€˜char_wbâ€™\n",
    "vec=TfidfVectorizer(min_df=0.01,stop_words='english',ngram_range=(1,2))\n",
    "counts=vec.fit_transform(X['text'])\n",
    "counts=counts.toarray()\n",
    "count_df1=pd.DataFrame(counts,columns=vec.get_feature_names())\n",
    "#count_df1=count_df1.drop(['amp','don'],axis=1)\n",
    "count_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(init='random', n_components=3, random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model1=NMF(n_components=3,init=\"random\",random_state=0)\n",
    "model1.fit(count_df1)\n",
    "#model1.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def top_words(X, model, component, num_words):\n",
    "    \"\"\"\n",
    "    Extract the top words from the specified component \n",
    "    for a topic model trained on data. \n",
    "    X: a term-document matrix, assumed to be a pd.DataFrame\n",
    "    model: a sklearn model with a components_ attribute, e.g. NMF\n",
    "    component: the desired component, specified as an integer. \n",
    "        Must be less than than the total number of components in model\n",
    "    num_words: the number of words to return.\n",
    "    \"\"\"\n",
    "    orders = np.argsort(model.components_, axis = 1)\n",
    "    important_words = np.array(X.columns)[orders]\n",
    "    return important_words[component][-num_words:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>track</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>playlist</td>\n",
       "      <td>enjoy</td>\n",
       "      <td>looking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tech</td>\n",
       "      <td>hope</td>\n",
       "      <td>similar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deep house</td>\n",
       "      <td>mix</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>feedback</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>new</td>\n",
       "      <td>remix</td>\n",
       "      <td>mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deep</td>\n",
       "      <td>video</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>house music</td>\n",
       "      <td>xb</td>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>music</td>\n",
       "      <td>amp xb</td>\n",
       "      <td>song</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>house</td>\n",
       "      <td>amp</td>\n",
       "      <td>track</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Topic 0   Topic 1  Topic 2\n",
       "0         good     track     love\n",
       "1     playlist     enjoy  looking\n",
       "2         tech      hope  similar\n",
       "3   deep house       mix   thanks\n",
       "4         like  feedback     help\n",
       "5          new     remix      mix\n",
       "6         deep     video     like\n",
       "7  house music        xb     know\n",
       "8        music    amp xb     song\n",
       "9        house       amp    track"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic1=pd.DataFrame({'Topic 0':top_words(count_df1, model1, 0, 10),\n",
    "                   'Topic 1':top_words(count_df1, model1, 1, 10),\n",
    "                   'Topic 2':top_words(count_df1, model1, 2, 10)})\n",
    "topic1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 0: social security/pension \\\n",
    "Topic 1: social media/life \\\n",
    "Topic 2: post/social medium/ins/facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=model1.fit_transform(count_df1)\n",
    "L=[]\n",
    "for i in W:\n",
    "    L.append(i.argmax())\n",
    "X['topic']=L\n",
    "t0=X[X.topic==0]\n",
    "t1=X[X.topic==1]\n",
    "t2=X[X.topic==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Emotion across topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-23-d62b398ca19f>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-d62b398ca19f>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    sia = SIA()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def sent_df(df):\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "    import my_module\n",
    "    import importlib\n",
    "    importlib.reload(my_module)\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    #create a list of dictionaries\n",
    "    sia = SIA()\n",
    "    results = []\n",
    "    words=[]\n",
    "\n",
    "    for line in df['text']:\n",
    "        D,pol_score=sid.polarity_scores(sia,text=line) #use customized module\n",
    "        pol_score['text'] = line\n",
    "        results.append(pol_score)\n",
    "        words.append(D)\n",
    "    #Extract sentiment words\n",
    "    D_p=[] # positive word and its sentiment score\n",
    "    D_n=[] # negative word and its sentiment score\n",
    "    D1=[] # only positive word\n",
    "    D2=[] # only negative word\n",
    "    for i in range(len(words)):\n",
    "        newDict = {key: value for (key, value) in words[i].items() if value != 0.0 }\n",
    "        newDict1 = {key: value for (key, value) in words[i].items() if value > 0.0 }\n",
    "        newDict2 = {key: value for (key, value) in words[i].items() if value < 0.0 }\n",
    "        D_p.append(newDict1)\n",
    "        D_n.append(newDict2)\n",
    "        D1.append(list(newDict1.keys()))\n",
    "        D2.append(list(newDict2.keys()))\n",
    "    #create a df to write in the results of sentiment analysis\n",
    "    sent = pd.DataFrame(results)\n",
    "    sent['p_word_dict']=D_p\n",
    "    sent['n_word_dict']=D_n\n",
    "    p=[]\n",
    "    n=[]\n",
    "    for i in D1:\n",
    "        p.append(' '.join(i))\n",
    "    for i in D2:\n",
    "        n.append(' '.join(i))\n",
    "    sent['total']=(sent.pos-sent.neg)/sent.neu    \n",
    "    sent['p_word']=p\n",
    "    sent['n_word']=n\n",
    "    sent['label']=0\n",
    "    sent['label'].loc[sent['total']> 0]=1\n",
    "    sent['label'].loc[sent['total']< 0]=-1\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'my_module' has no attribute 'polarity_scores'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-5cd8cf7b58cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msent_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'topic'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msent_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'topic'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-6a9b3ff34cd8>\u001b[0m in \u001b[0;36msent_df\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpol_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msia\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#use customized module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mpol_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpol_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'my_module' has no attribute 'polarity_scores'"
     ]
    }
   ],
   "source": [
    "a=sent_df(t0)\n",
    "a['topic']=0\n",
    "\n",
    "b=sent_df(t1)\n",
    "b['topic']=1\n",
    "\n",
    "c=sent_df(t2)\n",
    "c['topic']=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.concat([a,b,c],axis=0)\n",
    "final.total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.boxplot(x=\"topic\", y=\"total\", data=final,showfliers = False)\n",
    "ax.set(ylabel=\"Sentiment Score\",title=\"Sentiment Score by topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common positive/negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_pn(df):\n",
    "    positive=df.p_word[df['label']==1] #positive words in positive post\n",
    "    negative=df.n_word[df['label']==-1] #negative words in negative post\n",
    "    return positive,negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import collections\n",
    "def count_words(text):\n",
    "    all_words = list(itertools.chain(*text.str.split()))\n",
    "    counts = collections.Counter(all_words)\n",
    "    counts_df = pd.DataFrame(counts.most_common(100),\n",
    "                            columns=['words', 'count'])\n",
    "\n",
    "    return counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive,negative=sort_pn(final)\n",
    "p_n=pd.concat([count_words(positive)[:5],count_words(negative)[:5]])\n",
    "p_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive,negative=sort_pn(a)\n",
    "p_n=pd.concat([count_words(positive)[:5],count_words(negative)[:5]])\n",
    "p_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive,negative=sort_pn(b)\n",
    "p_n=pd.concat([count_words(positive)[:5],count_words(negative)[:5]])\n",
    "p_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive,negative=sort_pn(c)\n",
    "p_n=pd.concat([count_words(positive)[:5],count_words(negative)[:5]])\n",
    "p_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequency splitted by sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#nltk.download(\"stopwords\") #uncomment it when run it for the first time\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "stop_words.update({'would','k','im','could','also',\n",
    "                   'amp','much','one','like','get',\n",
    "                   'since','etc','got','always',\n",
    "                   'know','thing','really','dont',\n",
    "                   'find','even','go','time','need','want'\n",
    "                  })\n",
    "def remove_stopwords(text):\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "final['text']=final['text'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "def count_2gram(text):\n",
    "    all_words = list(itertools.chain(*text.str.split()))\n",
    "    es2grams = ngrams(all_words, 2)\n",
    "    counts = collections.Counter(es2grams)\n",
    "    count_df = pd.DataFrame(counts.most_common(100),\n",
    "                            columns=['words', 'count'])\n",
    "    dictionary2 = [' '.join(tup) for tup in count_df.words]\n",
    "    count_df.words=dictionary2\n",
    "\n",
    "    return count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pn_freq(df):\n",
    "    count_p=count_2gram(df['text'][df['label']>0.191186]) #>0.109797 #==1\n",
    "    count_n=count_2gram(df['text'][df['label']<-0.006572]) #<-0.001208 #==-1\n",
    "    return count_p,count_n\n",
    "\n",
    "p,n=pn_freq(final)\n",
    "p.head(10),n.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,n=pn_freq(final[final.topic==0])\n",
    "p.head(10),n.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,n=pn_freq(final[final.topic==1])\n",
    "p.head(10),n.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,n=pn_freq(final[final.topic==2])\n",
    "p.head(10),n.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling after sentiment splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec=TfidfVectorizer(min_df=0.01,stop_words='english',ngram_range=(1,2))\n",
    "counts=vec.fit_transform(final['text'][final['label']>0.191186]) #positive\n",
    "counts=counts.toarray()\n",
    "count_df1=pd.DataFrame(counts,columns=vec.get_feature_names())\n",
    "#count_df1=count_df1.drop(['amp','don'],axis=1)\n",
    "count_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model1=NMF(n_components=3,init=\"random\",random_state=1)\n",
    "model1.fit(count_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic2=pd.DataFrame({'Topic 0':top_words(count_df1, model1, 0, 10),\n",
    "                   'Topic 1':top_words(count_df1, model1, 1, 10),\n",
    "                   'Topic 2':top_words(count_df1, model1, 2, 10)})\n",
    "topic2\n",
    "# 'Topic 4':top_words(count_df1, model1, 4, 10),\n",
    "#                     'Topic 5':top_words(count_df1, model1, 5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pay house/loan/car \\\n",
    "retirement \\\n",
    "credit card \\\n",
    "school friend feel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=TfidfVectorizer(min_df=0.01,stop_words='english',ngram_range=(1,2))\n",
    "counts=vec.fit_transform(final['text'][final['label']<-0.006572]) #negative\n",
    "counts=counts.toarray()\n",
    "count_df2=pd.DataFrame(counts,columns=vec.get_feature_names())\n",
    "#count_df1=count_df1.drop(['amp','don'],axis=1)\n",
    "count_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=NMF(n_components=3,init=\"random\",random_state=0)\n",
    "model2.fit(count_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic3=pd.DataFrame({'Topic 0':top_words(count_df2, model2, 0, 10),\n",
    "                   'Topic 1':top_words(count_df2, model2, 1, 10),\n",
    "                   'Topic 2':top_words(count_df2, model2, 2, 10)})\n",
    "topic3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "live home/parent \\\n",
    "credit card and insurance \\\n",
    "retirement \\\n",
    "parent talking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all adj. related to parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "#nltk.download('punkt')\n",
    "sentence=df['selftext'].apply(lambda x: sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parent(sentence_ele):\n",
    "    L=[]\n",
    "    for i in sentence_ele:\n",
    "        if 'time' in i: \n",
    "            L.append(i)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_sentence=sentence.apply(lambda x: extract_parent(x))\n",
    "' '.join(parent_sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokens=nltk.word_tokenize(parent_sentence[39][1])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')\n",
    "def extract_adj(sentence_ele):\n",
    "    adjs=[]\n",
    "    for i in sentence_ele:\n",
    "        tokens=nltk.word_tokenize(i)\n",
    "        df_type=pd.DataFrame(nltk.pos_tag(tokens),columns=['words', 'type'])\n",
    "        adjs=list(df_type[df_type.type=='JJ'].words)\n",
    "    return ' '.join(adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjs=parent_sentence.apply(lambda x: extract_adj(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec=TfidfVectorizer(max_df=0.5,min_df=0.01,stop_words='english',ngram_range=(1,2))\n",
    "counts=vec.fit_transform(adjs)\n",
    "counts=counts.toarray()\n",
    "count_df1=pd.DataFrame(counts,columns=vec.get_feature_names())\n",
    "#count_df1=count_df1.drop(['amp','don'],axis=1)\n",
    "count_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model1=NMF(n_components=3,init=\"random\",random_state=0)\n",
    "model1.fit(count_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic1=pd.DataFrame({'Topic 0':top_words(count_df1, model1, 0, 10),\n",
    "                   'Topic 1':top_words(count_df1, model1, 1, 10),\n",
    "                   'Topic 2':top_words(count_df1, model1, 2, 10)})\n",
    "topic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all words across rows\n",
    "import itertools\n",
    "import collections\n",
    "def count_words(text):\n",
    "    all_words = list(itertools.chain(*text.str.split()))\n",
    "    counts = collections.Counter(all_words)\n",
    "    counts_df = pd.DataFrame(counts.most_common(100),\n",
    "                            columns=['words', 'count'])\n",
    "\n",
    "    return counts_df\n",
    "count_words(adjs).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.update({'i','*','im','â€™','much'})\n",
    "adjs=adjs.apply(lambda x: remove_stopwords(x))\n",
    "count_df=count_words(adjs)\n",
    "count_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
